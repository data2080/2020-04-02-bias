---
layout: handouts
slideset: slides
permalink: handout/
---



# Welcome to class 9

The next two classes will be about bias and fairness. First we'll talk about how AI systems become biased. We will look at this through a variety of lenses to get a broad view. We will examine both case studies of popular cases and more academic audits. This week we'll focus on understanding bias. We'll get specific about what it means for an AI system to be biased and how AI systems produce biased decisions.


<hr>

# Readings

[Propublica Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) this is a classic article in the fair machine learning community. In class, we'll work with their data and reproduce their results.

[Fair ML Book Classification Chapter](https://fairmlbook.org/pdf/classification.pdf) This textbook chapter lays out how nondiscrimination can be defined. In reading, keep track of the various definitions that appear and the running examples. Skip over the problem set and read the last bit of the chapter.


<hr>


# Bias Audit Checklist

target audience:
- team that built the system
- journalist pitch
- impacted person's lawyer

1. Identify the system with link
1. Summarize what it does (input, output, etc)
1. What sources of bias might this system be susceptible to?
1. What statistical structures might you expect?
1. What questions would you ask about the data used for training?
1. What EDA would you do if you had access to the training data?
1. What type of audit would you recommend?
1. What data would be needed for an audit?
1. What type of fairness metric(s) would you recommend for this and why?

